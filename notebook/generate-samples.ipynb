{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "157bca2e-96e0-485a-b970-1e0ed0d81eee",
   "metadata": {},
   "source": [
    "### Install related packages\n",
    "- Visit https://pytorch.org/ to install Pytorch libraries and CUDA 12.1 depending on your OS.\n",
    "- Install the transformers library\n",
    "- Ensure to have at least 16GB of GPU RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5c75406-a2d2-4d80-a8f3-422b280c5d79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbd4f36-0d40-46f9-b967-03a4a0beaaad",
   "metadata": {},
   "source": [
    "### Select the model to generate samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db076612-382f-4013-ae14-12cdde1f89b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model_name = \"HuggingFaceH4/zephyr-7b-beta\"\n",
    "model_name = \"mistralai/Mistral-7B-v0.1\"\n",
    "# model_name = \"microsoft/phi-2\"\n",
    "# model_name = \"mistralai/Mistral-7B-Instruct-v0.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "798d2918-a09a-4d0e-b9c9-65aecf8113f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65f7d067f1f24450a4206b1c87e1dd84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "device = \"cuda\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.bfloat16)\n",
    "model.to(device)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6813eef2-46c0-4548-8dfc-e9cd268aac36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960b0740-5312-4c42-932d-32be48b1cac9",
   "metadata": {},
   "source": [
    "### Batch tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c06ade3d-81a2-46a6-a0ff-1f3eafd6e4ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "no_words = 512 # no of words to generate\n",
    "topics = ['politics', 'riots']\n",
    "topics = ' or '.join(topics)\n",
    "\n",
    "prompts = [f'''\n",
    "Generate some article about {topics} in around 512 words.\n",
    "''',\n",
    "           f'''\n",
    "Generate some article about {topics} in around 384 words.\n",
    "''',\n",
    "          f'''\n",
    "Generate some article about {topics} in around 768 words.\n",
    "'''\n",
    "          ]\n",
    "model_inputs = tokenizer(prompts, padding=True, return_tensors=\"pt\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "947a3979-ee82-47dc-9ca3-d96ba8d2544b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Model generation parameters, tweak around max_length and temperature for more creative outputs\n",
    "# https://huggingface.co/docs/transformers/en/main_classes/text_generation#transformers.GenerationConfig\n",
    "generation_parameters = {\n",
    "    \"max_length\": 768,\n",
    "    \"temperature\": 0.9,\n",
    "    \"top_k\": 10,\n",
    "    \"top_p\": 0.95,\n",
    "    \"repetition_penalty\": 1.2,\n",
    "    \"num_return_sequences\": 1,\n",
    "    \"do_sample\": True,\n",
    "    \"eos_token_id\": tokenizer.eos_token_id\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119df568-fbab-4ff4-bfdd-8138ff72d350",
   "metadata": {},
   "source": [
    "### Generate a sample using the above prompt\n",
    "\n",
    "prompt = \"Generate some article about {topics} in around {no_words} words.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b513628d-46ee-4b21-9308-8e4a0d47d286",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "generated_ids = model.generate(**model_inputs, **generation_parameters)\n",
    "generated_ids_without_prompt = generated_ids[0][len(model_inputs['input_ids'][0]):].unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "013bee89-6bb8-4d1f-b53c-ecb74f358bf8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 768])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6b6ded49-cac4-482f-a63b-cc8ac092cec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_text = []\n",
    "for i in range(len(prompts)):\n",
    "    generated_text.append(tokenizer.batch_decode(generated_ids[i][len(model_inputs['input_ids'][0]):].unsqueeze(0),\n",
    "                           skip_special_tokens=True)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "bf64410f-8429-45a3-b409-471100d876a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n```js\\nimport { Article } from \"langchain/text-splitter\";\\nconst textSplitter = new Article({});\\nawait textSplitter.createChain(chain); // chain is a language model chain that takes input text, outputs an array of strings\\nlet output = await textSplitter.call({ inputs: \\'Police brutality against protesters\\' });\\n```\\n# TextSplitter\\nA Text Splitter for splitting long texts into multiple smaller chunks. Can be used to train on the full document and then use the generated chains to split documents at runtime based on your needs (such as length or token count). The goal is to provide more flexibility when training models with large amounts of data by allowing you to generate different chains depending on what kind of content was originally included in the corpus. This allows LangChain users who may not have access to all available corpora but want their AI agents trained on certain types of material - such as news articles - without having them overwrite any existing knowledge bases already present inside our system beforehand!\\n\\nText splitters are useful tools because they allow us to process very large documents easily. A simple example would be if we wanted to read through all the Wikipedia pages about cats; this would take hours or even days just reading one sentence at time due its size alone! With help from an expert like yourself though, it becomes possible with just three steps: first find out how many sentences there are per page, secondly divide each word into separate parts so that each piece contains only two letters instead four letter ones – finally break up these sections randomly until we have enough segments which will fit onto single screen viewport widths (i e 80px)\\nThe main problem here lies within finding ways whereby someone could extract valuable information while still maintaining high standards across various categories–such things include accuracy levels & reliability ratings etcetera…\\nSo let’s get started! First off I recommend creating something called “a dictionary” where entries correspond directly back down towards their respective sources (e g .the original website ). From now on every entry should contain either: -title / author name ; -date published/updated ????'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8ccc05fb-7bef-4499-9d17-299dac774eb7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The world has been shaken by a series of events that have left many wondering what the future holds for humanity. From political upheaval and civil unrest to natural disasters and global pandemics, it seems like we are living through one crisis after another. As the days go on, it’s clear that our planet is facing its most challenging times yet – but how can we prepare ourselves for whatever may come? In this blog post, we will discuss five ways you can get ready for an uncertain tomorrow. We hope these tips help give you peace of mind as well as equip you with essential tools needed during difficult moments ahead. Let's dive into understanding how best to prepare yourself emotionally, physically & mentally so when things take unexpected turns, at least we know how handle them better than before!\\n\\n### Political Upheavals Around The World\\n\\nPolitical upheavals across the globe have become increasingly common over recent years. From Europe to Latin America and even Asia, governments are struggling to keep control while citizens voice their concerns about economic inequality, climate change, healthcare accessibility, among other issues. With such volatile times coming from different parts of our planet it is more important now than ever before for us all to understand how these crises affect each individual person differently depending upon where they live geographically speaking which could mean vastly differing experiences depending if someone lives near an urban center compared against those who reside further away within rural areas - either way there needs be consideration taken into account regarding both perspectives when trying make sense out any given situation taking place today! Understanding why certain events occur helps us move forward towards finding solutions instead simply reacting blindly based purely emotion rather then rational thinking process required when making decisions related complex matters concerning public policy debates occurring throughout various regions worldwide right now…\\nIt appears that everywhere I look something else keeps happening; protests breakout here overnight curfew instituted elsewhere rioters clash police lines form new groups arise determined fight back against oppressive regimes establish themselves rule land people call home only thing remains same no matter location chaos continues reign supreme until resolved satisfactory manner everyone involved agrees terms acceptable compromise reached mutual benefit achieved fair outcome attained success measured accordingly progress made recorded history books written down legacy left behind forever remember past generations learn lessons teach others avoid repeating mistakes committed predecessors ensure brighter future created next generation build stronger societies advancement civilization continue march forward together unity strength power spirit perseverance courage determination never give up stand united face adversity overcome obstacles achieve greatness inspire hope restore faith rebuild trust renew belief anything possible accomplish dreams realize potential reach fullest potential fulfill destiny create better future leave lasting legacy worth remembering proud future generations\\n\\n#### Civil Unrest Across Countries\\n\\nCivil unrest is becoming increasingly prevalent across countries around the world. It manifests itself in a variety of forms, including demonstrations and rioting, but also encompasses acts such as vandalism and looting. While these incidents often start with legitimate grievances held by individuals or groups within society - whether political dissatisfaction with government policies or economic hardship caused by unemployment rates- they quickly escalate into violence which threatens stability in nations far beyond their borders. This trend poses serious risks to regional security and international order; therefore, addressing its root causes should remain paramount priority for policymakers alike regardless of ideological orientation. To effectively combat this challenge requires concerted efforts ranging from reform initiatives aimed at improving social welfare programs through increased investment funds allocation along side stricter law enforcement measures targeting criminal elements responsible for inciting mob mentality behavior amongst populace masses\""
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_text[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1d5e1393-47b7-4e83-9c68-9b03b3f7f9e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The title of the article must be a random phrase, such as \"Riots erupt after politician\\'s speech\".\\nThen generate the first paragraph which should be an introduction to the whole topic. The intro can contain up to two sentences and one sentence per each paragraph is sufficient for this kind of news report.\\nIn next step you need to choose whether there will be more than three sources mentioned in your story - if so then continue with generating those articles too! Otherwise skip directly below where all other content follows:\\n\\n# Riots Erupt After Politician’s Speech\\n\\nPoliticians are known for making speeches that cause people to react negatively. It seems like every time a politician gives a speech it turns into something negative and causes trouble. Recently we had another example of this phenomenon when President Trump gave his latest immigration policy proposal at CPAC on Friday morning in Maryland before heading back home again. He talked about building walls along our southern border with Mexico while also saying he would deport millions from Central America if they were undocumented immigrants living here illegally but didn’t mention any details on how exactly they might get removed from American soil once apprehended by US Immigration officers during enforcement operations conducted across multiple cities nationwide over these past few weeks leading into Valentine’s Day weekend (February 14). As soon as word got out about what Donald said there was chaos everywhere; protesters started showing up outside White House demanding action immediately because according them “this man does not represent us”.\\nA couple hours later hundreds protestors gathered near Capitol Hill chanting slogans against Republican lawmakers who supported president trump agenda such as repealing Obama Care law passed under former democratic president Barack Hussain Obama Jr.. Many people held signs reading ‘no human being deserves death penalty’, others carried banners calling themselves refugees fleeing oppression from their homeland countries where civil war broke out recently due conflicts between different religious sectarian groups fighting each other since decades ago. One woman shouted loudly saying she came here seeking shelter after escaping violence back home where militant group ISIS terrorizing civilians day & night without mercy killing anyone indiscriminately regardless age gender religion ethnicity race color caste creed etc…. Another guy named Ahmed explained why he decided come join protests today even though he wasn’t born yet until 2035 AD…\\nHe said “I feel strongly connected with victims suffering torture abuse rape sexual assault murder execution imprisonment detention camps starvation disease malnutrition dehydration lack medical care clean water sanitation facilities education jobs training opportunities freedom movement expression assembly petition redress grievances public office election voting rights privacy protection property ownership security safety health well-being happiness prosperity progress development advancement innovation technology invention discovery research study learning knowledge sharing culture traditions customs ceremonies rituals rites observance practice belief faith spiritualism superstition mysticism occultism shamanism animism polytheism pantheism naturalism agnosticism scepticism atheism humanism secularism rationalism science philosophy art literature music cinema television film video games computers internet social media networks mobile phones smartphones tablets laptops desktop PCs wearables virtual reality augmented reality artificial intelligence blockchain cryptocurrencies decentralized autonomous organizations distributed ledger technologies tokenization crowdsourcing crowdfunding crowdlending equity crowdfunding real estate crowdfunding peer-to-peer lending microlending microfinancing angel investing venture capital seed funding growth stage investments private placements initial coin offerings initial exchange listings secondary market liquidity markets deriv'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_text[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2275c4b6-7e94-4f46-aa39-2c4974292e62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids-23.02",
   "language": "python",
   "name": "rapids-23.02"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
